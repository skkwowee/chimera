# Chimera — Session Progress

## Project
CS2 VLM research. Two-stage training: SFT (vision) → GRPO (reasoning) for Qwen3.5-27B.
- SFT: teach model to read the HUD — synchronize perceived game state with demo ground truth
- GRPO: teach model strategic reasoning — decisions scored against pro play + round outcomes

## Pipeline Status
- [x] F01 — Data schema & manifest
- [x] F02 — Demo data pipeline & viewer (4 demos, 83 rounds, 563 kills)
- [ ] F03 — Screenshot-demo synchronization (NEXT)
- [ ] F04 — SFT training — visual grounding
- [ ] F05 — GRPO dataset from demos
- [ ] F06 — GRPO training — strategic reasoning
- [ ] F07 — Evaluation & analysis

## What changed this session (2026-02-20)
- Planned F03: screenshot-demo synchronization via CS2 demo playback
- Key decision: tournament VODs have custom overlays that don't generalize.
  Instead, play back .dem files in CS2's built-in demo player → standard HUD.
- Approach: CS2 netcon (TCP console via -netconport) driven from WSL Python.
  Jump to specific ticks, control spectator POV, capture JPEGs automatically.
- Match identified: IEM Kraków 2026 Grand Final, Vitality 3-1 FURIA
  (Mirage 13-11, Inferno 13-8, Nuke 13-2, Overpass 13-10)
- Tickrate confirmed ~90Hz (SourceTV). 17 columns in Parquet per tick.
- Expected yield: ~3,500-5,000 labeled screenshots across 4 maps.
- Scripts to write: src/netcon.py, scripts/plan_captures.py,
  scripts/capture_screenshots.py, scripts/generate_sft_labels.py

## What changed last session (2026-02-15)
- Rewrote reward functions: 3-signal architecture (D013) with multiplicative
  format gate. R_percept=0.20, R_decision=0.30, R_outcome=0.50, KL λ=0.02.
- Updated grpo_trainer.py, train_grpo.py, config.yaml, __init__.py to match.
- Clarified pipeline: old "strategy pre-training on text" phase is cut.
  SFT is on screenshots (vision), GRPO is on demo data (reasoning).
- Ground truth for SFT comes from demo data synced to video frames.
  Demo data = engine truth (exact health, armor, weapons, etc.).

## Key design decisions
- SFT ground truth: demo-to-VOD synchronization, not model labeling
- GRPO reward asymmetry: deviating from a winning pro play is NOT penalized
  hard (model's alternative might work), but endorsing a losing play is
- Reward architecture (D013): multiplicative format gate + 3 signals:
  R_percept=0.20, R_decision=0.30, R_outcome=0.50, KL λ=0.02
- Additional RL on video/screenshot data: TBD, user is contemplating

## Next step: F03 — Screenshot capture via CS2 demo playback
Approach: netcon TCP automation from WSL → CS2 on Windows.
1. plan_captures.py — select ticks + POV players from Parquet (offline)
2. capture_screenshots.py — drive CS2 via netcon: goto_tick, spec_player, jpeg
3. generate_sft_labels.py — build game_state JSON labels from Parquet (offline)
User must: set CS2 launch option -netconport 2121, copy .dem files to Windows path.

## Data available
- 4 parsed demos: Furia vs Vitality (Mirage, Inferno, Nuke, Overpass)
- Parquet files in data/processed/demos/ with full-tick player state
- Viewer data in site/public/viewer-data/

## Files modified this session
- claude-progress.txt — updated with F03 plan
